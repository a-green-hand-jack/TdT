#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®æ•°æ®æ¼”ç¤ºå®Œæ•´çš„LLM Agentç³»ç»Ÿ

å±•ç¤ºä½¿ç”¨æˆ‘ä»¬è®¾è®¡çš„å®Œæ•´å·¥å…·é“¾ï¼šæƒåˆ©è¦æ±‚ä¹¦ã€æ ‡å‡†åŒ–åºåˆ—JSONã€ç°æœ‰è§„åˆ™å’Œä¸“é—¨çš„æç¤ºæ¨¡æ¿ã€‚
"""

import json
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from tdt.core.data_loader import DataLoader
from tdt.core.llm_agent import LLMRuleAgent
from tdt.agents.prompts import format_claims_for_llm, format_sequence_summary, format_existing_rules


def demo_real_agent_system():
    """æ¼”ç¤ºå®Œæ•´çš„Agentç³»ç»Ÿ"""
    print("ğŸ§¬ TDTä¸“åˆ©è§„åˆ™ç”ŸæˆAgent - çœŸå®æ•°æ®æ¼”ç¤º")
    print("=" * 70)
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
    api_key = os.getenv('QWEN_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° QWEN_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® QWEN_API_KEY")
        return
    
    try:
        # 1. åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨å’ŒLLM Agent
        print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        data_loader = DataLoader()
        llm_agent = LLMRuleAgent(api_key=api_key, model="qwen-plus")
        
        # 2. åŠ è½½çœŸå®æ•°æ®
        print("ğŸ“ åŠ è½½çœŸå®æ•°æ®...")
        
        # åŠ è½½æƒåˆ©è¦æ±‚ä¹¦
        claims_path = Path("output/markdowns/CN118284690A_claims.md")
        print(f"   ğŸ“„ æƒåˆ©è¦æ±‚ä¹¦: {claims_path}")
        claims_doc = data_loader.load_claims_markdown(claims_path)
        
        # åŠ è½½æ ‡å‡†åŒ–åºåˆ—JSON
        sequence_path = Path("output/sequences/CN118284690A.json")
        print(f"   ğŸ§¬ åºåˆ—æ–‡ä»¶: {sequence_path}")
        sequence_data = data_loader.load_sequence_json(sequence_path)
        
        # åŠ è½½ç°æœ‰è§„åˆ™
        rules_path = Path("Patents/patent rules_rules.json")
        print(f"   ğŸ“‹ ç°æœ‰è§„åˆ™: {rules_path}")
        existing_rules = data_loader.load_existing_rules(rules_path)
        
        print("âœ… æ•°æ®åŠ è½½å®Œæˆï¼")
        print(f"   ä¸“åˆ©å·: {claims_doc.patent_number}")
        print(f"   æƒåˆ©è¦æ±‚æ•°: {claims_doc.total_claims}")
        print(f"   åºåˆ—æ•°: {len(sequence_data.sequences)}")
        print(f"   ç°æœ‰è§„åˆ™æ•°: {len(existing_rules.get('rules', []))}")
        print(f"   SEQ IDå¼•ç”¨: {claims_doc.total_seq_id_references}")
        print(f"   çªå˜æ¨¡å¼: {claims_doc.mutation_pattern_count}")
        
        # 3. åˆ›å»ºåºåˆ—ä¸æƒåˆ©è¦æ±‚çš„æ˜ å°„
        print("\nğŸ”— åˆ›å»ºåºåˆ—ä¸æƒåˆ©è¦æ±‚æ˜ å°„...")
        sequence_mapping = data_loader.create_sequence_claims_mapping(claims_doc, sequence_data)
        print(f"   æ˜ å°„ç»Ÿè®¡: {sequence_mapping.mapping_statistics}")
        
        # 4. ä½¿ç”¨æˆ‘ä»¬è®¾è®¡çš„æ ¼å¼åŒ–å‡½æ•°
        print("\nğŸ“ æ ¼å¼åŒ–æ•°æ®ä¾›LLMåˆ†æ...")
        claims_content = format_claims_for_llm(claims_doc)
        sequence_summary = format_sequence_summary(sequence_data)
        existing_rules_summary = format_existing_rules(existing_rules)
        
        print(f"   æƒåˆ©è¦æ±‚å†…å®¹é•¿åº¦: {len(claims_content)} å­—ç¬¦")
        print(f"   åºåˆ—æ‘˜è¦é•¿åº¦: {len(sequence_summary)} å­—ç¬¦")
        print(f"   ç°æœ‰è§„åˆ™æ‘˜è¦é•¿åº¦: {len(existing_rules_summary)} å­—ç¬¦")
        
        # 5. æ˜¾ç¤ºåˆ†æçš„æ•°æ®æ ·æœ¬
        print("\nğŸ“Š æ•°æ®åˆ†ææ ·æœ¬:")
        print("=" * 50)
        
        print("æƒåˆ©è¦æ±‚ä¹¦æ ·æœ¬ (å‰500å­—ç¬¦):")
        print("-" * 30)
        print(claims_content[:500])
        print("...")
        
        print("\nåºåˆ—æ•°æ®æ ·æœ¬:")
        print("-" * 30)
        print(sequence_summary)
        
        print("\nç°æœ‰è§„åˆ™æ ·æœ¬:")
        print("-" * 30)
        print(existing_rules_summary)
        
        # 6. ä½¿ç”¨LLM Agentè¿›è¡Œåˆ†æ (ä½¿ç”¨è¾ƒçŸ­çš„æ•°æ®é¿å…è¶…å‡ºtokené™åˆ¶)
        print("\nğŸ¤– ä½¿ç”¨LLM Agentåˆ†æä¸“åˆ©...")
        print("æ³¨æ„ï¼šç”±äºæ•°æ®é‡åºå¤§ï¼Œè¿™é‡Œä½¿ç”¨å‰3ä¸ªæƒåˆ©è¦æ±‚è¿›è¡Œæ¼”ç¤º")
        
        # åˆ›å»ºç®€åŒ–çš„æƒåˆ©è¦æ±‚æ–‡æ¡£ç”¨äºæ¼”ç¤º
        simplified_claims_doc = create_simplified_claims_doc(claims_doc)
        
        # ä½¿ç”¨LLMè¿›è¡Œåˆ†æ
        result = llm_agent.analyze_patent_claims(
            simplified_claims_doc, 
            existing_rules, 
            sequence_data
        )
        
        print("âœ… LLMåˆ†æå®Œæˆï¼")
        print(f"   åˆ†æç½®ä¿¡åº¦: {result.analysis_confidence:.2%}")
        print(f"   ç”Ÿæˆçš„ä¿æŠ¤è§„åˆ™æ•°: {len(result.protection_rules)}")
        print(f"   å¤æ‚åº¦çº§åˆ«: {result.complexity_analysis.complexity_level}")
        print(f"   å›é¿ç­–ç•¥æ•°: {len(result.avoidance_strategies)}")
        
        # 7. æ˜¾ç¤ºåˆ†æç»“æœ
        display_analysis_results(result)
        
        # 8. æ¼”ç¤ºè§„åˆ™å¤æ‚åº¦è¯„ä¼°
        if result.protection_rules:
            print("\nğŸ“ˆ æ¼”ç¤ºè§„åˆ™å¤æ‚åº¦è¯„ä¼°...")
            first_rule = result.protection_rules[0]
            complexity = llm_agent.evaluate_rule_complexity(first_rule.dict())
            print(f"   è§„åˆ™å¤æ‚åº¦: {complexity.complexity_level}")
            print(f"   å¤æ‚åº¦è¯„åˆ†: {complexity.complexity_score:.1f}/10")
            print(f"   è¡¨è¾¾å»ºè®®: {complexity.representation_suggestion}")
        
        # 9. æ¼”ç¤ºå›é¿ç­–ç•¥ç”Ÿæˆ
        print("\nğŸ›¡ï¸ æ¼”ç¤ºå›é¿ç­–ç•¥ç”Ÿæˆ...")
        if result.protection_rules:
            strategies = llm_agent.generate_avoidance_strategies(
                {"rules": [rule.dict() for rule in result.protection_rules[:2]]},
                {"sequences": [seq.dict() for seq in sequence_data.sequences[:1]]}
            )
            print(f"   ç”Ÿæˆç­–ç•¥æ•°: {len(strategies)}")
            for i, strategy in enumerate(strategies[:2], 1):
                print(f"   ç­–ç•¥ {i}: {strategy.strategy_type}")
                print(f"      ç½®ä¿¡åº¦: {strategy.confidence_score:.2%}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def create_simplified_claims_doc(original_doc):
    """åˆ›å»ºç®€åŒ–çš„æƒåˆ©è¦æ±‚ä¹¦æ–‡æ¡£ç”¨äºæ¼”ç¤º"""
    # åªå–å‰3ä¸ªæƒåˆ©è¦æ±‚è¿›è¡Œæ¼”ç¤º
    simplified_claims = original_doc.claims[:3]
    
    from tdt.models.claims_models import ClaimsDocument
    
    simplified_doc = ClaimsDocument(
        patent_number=original_doc.patent_number,
        source_file=original_doc.source_file,
        total_claims=len(simplified_claims),
        claims=simplified_claims
    )
    
    return simplified_doc


def display_analysis_results(result):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    print("\nğŸ“‹ LLMåˆ†æç»“æœ:")
    print("=" * 50)
    
    print(f"ğŸ“„ ä¸“åˆ©å·: {result.patent_number}")
    print(f"ğŸ¯ åˆ†æç½®ä¿¡åº¦: {result.analysis_confidence:.2%}")
    print(f"ğŸ”¬ ä½¿ç”¨æ¨¡å‹: {result.llm_model}")
    print(f"â±ï¸ åˆ†ææ—¶é—´: {result.generation_timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # å¤æ‚åº¦åˆ†æ
    complexity = result.complexity_analysis
    print(f"\nğŸ“ˆ å¤æ‚åº¦åˆ†æ:")
    print(f"   å¤æ‚åº¦çº§åˆ«: {complexity.complexity_level}")
    print(f"   å¤æ‚åº¦è¯„åˆ†: {complexity.complexity_score:.1f}/10")
    print(f"   çªå˜ä½ç‚¹æ•°: {complexity.mutation_count}")
    print(f"   è¡¨è¾¾å»ºè®®: {complexity.representation_suggestion}")
    
    # ä¿æŠ¤è§„åˆ™
    if result.protection_rules:
        print(f"\nğŸ›¡ï¸ ä¿æŠ¤è§„åˆ™ ({len(result.protection_rules)}æ¡):")
        for i, rule in enumerate(result.protection_rules[:3], 1):  # åªæ˜¾ç¤ºå‰3æ¡
            print(f"   è§„åˆ™ {i}: {rule.rule_id}")
            print(f"      ç±»å‹: {rule.rule_type}")
            print(f"      ä¿æŠ¤èŒƒå›´: {rule.protection_scope}")
            print(f"      å¤æ‚åº¦: {rule.complexity_score:.1f}/10")
            if rule.identity_threshold:
                print(f"      åŒä¸€æ€§é˜ˆå€¼: {rule.identity_threshold:.1%}")
    
    # å›é¿ç­–ç•¥
    if result.avoidance_strategies:
        print(f"\nğŸ¯ å›é¿ç­–ç•¥ ({len(result.avoidance_strategies)}ä¸ª):")
        for i, strategy in enumerate(result.avoidance_strategies[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ª
            print(f"   ç­–ç•¥ {i}: {strategy.strategy_type}")
            print(f"      æè¿°: {strategy.description[:100]}...")
            print(f"      ç½®ä¿¡åº¦: {strategy.confidence_score:.2%}")
    
    # åˆ†ææ‘˜è¦
    if result.analysis_summary:
        print(f"\nğŸ“Š åˆ†ææ‘˜è¦:")
        for key, value in result.analysis_summary.items():
            if isinstance(value, (int, float, str)):
                print(f"   {key}: {value}")


def main():
    print("ğŸš€ å¯åŠ¨çœŸå®æ•°æ®Agentæ¼”ç¤º...")
    print("ä½¿ç”¨å®Œæ•´å·¥å…·é“¾ï¼šDataLoader + LLMRuleAgent + ä¸“ç”¨æç¤ºæ¨¡æ¿")
    print()
    
    if demo_real_agent_system():
        print("\nâœ… å®Œæ•´Agentç³»ç»Ÿæ¼”ç¤ºæˆåŠŸï¼")
        print("\nğŸ’¡ ç³»ç»Ÿç‰¹ç‚¹:")
        print("â€¢ ä½¿ç”¨çœŸå®çš„æƒåˆ©è¦æ±‚ä¹¦æ•°æ® (130ä¸ªæƒåˆ©è¦æ±‚)")
        print("â€¢ å¤„ç†æ ‡å‡†åŒ–åºåˆ—JSON (6,775ä¸ªåºåˆ—)")
        print("â€¢ æ•´åˆç°æœ‰è§„åˆ™æ•°æ® (207æ¡è§„åˆ™)")
        print("â€¢ ä½¿ç”¨ä¸“é—¨è®¾è®¡çš„æç¤ºæ¨¡æ¿")
        print("â€¢ è‡ªåŠ¨è¯†åˆ«SEQ IDå¼•ç”¨å’Œçªå˜æ¨¡å¼")
        print("â€¢ æ™ºèƒ½ç”Ÿæˆä¿æŠ¤è§„åˆ™å’Œå›é¿ç­–ç•¥")
        print("â€¢ æä¾›å¤æ‚åº¦è¯„ä¼°å’Œè¡¨è¾¾å»ºè®®")
        print("\nğŸ”§ å®Œæ•´åŠŸèƒ½:")
        print("è¿™ä¸ªæ¼”ç¤ºå±•ç¤ºäº†æˆ‘ä»¬ç²¾å¿ƒè®¾è®¡çš„å®Œæ•´Agentå·¥å…·é“¾çš„çœŸå®åº”ç”¨èƒ½åŠ›ï¼")
    else:
        print("\nâŒ æ¼”ç¤ºå¤±è´¥")


if __name__ == "__main__":
    main()
